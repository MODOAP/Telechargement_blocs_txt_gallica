{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tTQfLyIKMpOn"
   },
   "source": [
    "# ModOAP - Téléchargement des blocs de texte de documents BNF / Gallica\n",
    "\n",
    "Ce carnet propose de spécifier l'**identifiant ark** d'un document ou une **liste d'identifiants** dans un fichier excel, pour **télécharger les blocs de texte** dans un fichier structuré au format **json**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "form",
    "id": "DPEj_4bOQBwV"
   },
   "outputs": [],
   "source": [
    "#@markdown ### Préparation et connexion à un compte Google Drive\n",
    "#@markdown Lancer cette cellule, puis cliquer sur le lien généré par Google pour connecter un compte Drive si demandé.\n",
    "\n",
    "import requests\n",
    "from openpyxl import load_workbook\n",
    "import urllib.request, urllib.error, urllib.parse\n",
    "from urllib.error import HTTPError, URLError\n",
    "import os\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "try :\n",
    "  import xmltodict\n",
    "except :\n",
    "  !pip install xmltodict\n",
    "  import xmltodict\n",
    "\n",
    "# chargement d'un google drive\n",
    "if not os.path.exists(\"/content/drive/MyDrive/\") :\n",
    "  drive.mount('/content/drive/')\n",
    "\n",
    "def get_var_ts(ts) :\n",
    "  # In : text string (mot) (ordered dict key, list ou dict)\n",
    "  # ajoute le contenu du mot au contenu du bloc texte\n",
    "  if isinstance(ts, list) :\n",
    "    for mot in ts :\n",
    "      contenu = mot[\"@CONTENT\"]\n",
    "      text_block_words.append(contenu)\n",
    "  else :\n",
    "    contenu = ts[\"@CONTENT\"]\n",
    "    text_block_words.append(contenu)\n",
    "\n",
    "def get_content(tlentry) :\n",
    "  # In : textline (ordered dict key, list ou dict)\n",
    "  # lance get_var_ts\n",
    "  if isinstance(tlentry, list) :\n",
    "    for tl in tlentry :\n",
    "      get_var_ts(tl[\"String\"])\n",
    "  else : get_var_ts(tlentry[\"String\"])\n",
    "\n",
    "def get_var_tb(tb) :\n",
    "  # In : textblock (ordered dict key, dict)\n",
    "  # récupère la position et l'id du bloc texte\n",
    "  # lance get_var_tb\n",
    "  width = tb[\"@WIDTH\"]\n",
    "  height = tb[\"@HEIGHT\"]\n",
    "  hpos = tb[\"@HPOS\"]\n",
    "  vpos = tb[\"@VPOS\"]\n",
    "  id = tb[\"@ID\"]\n",
    "  get_content(tb[\"TextLine\"])\n",
    "  return width, height, hpos, vpos, id\n",
    "\n",
    "def get_tb(tb_entry) :\n",
    "  # In : textblock (ordered dict key, list ou dict)\n",
    "  # récupère la position et l'id du bloc texte\n",
    "  # lance get_var_tb\n",
    "  if isinstance(tb_entry, list) :\n",
    "    for tb in tb_entry :\n",
    "      width, height, hpos, vpos, id = get_var_tb(tb)\n",
    "  else : \n",
    "    width, height, hpos, vpos, id = get_var_tb(tb_entry)\n",
    "  return width, height, hpos, vpos, id\n",
    "\n",
    "def block_treatment(tb, num_page) :\n",
    "  # In :  textblock (ordered dict key), numéro de page (int)\n",
    "  # lance get_tb\n",
    "  # ajoute la position et le contenu du bloc texte dans un dictionnaire\n",
    "  global text_block_words\n",
    "  text_block_words = []\n",
    "  width, height, hpos, vpos, id = get_tb(tb)\n",
    "  contenu = \" \".join(text_block_words)\n",
    "  position_dic = {\"width\" : width, \"height\" : height, \"hpos\" : hpos, \"vpos\" : vpos}\n",
    "  dico_id = {\"Page_Num\" : num_page, \"Position\" : position_dic, \"Content\" : contenu}\n",
    "  text_blocks[id] = dico_id\n",
    "\n",
    "def infos_doc(ark):\n",
    "  # In :  identifiant ark\n",
    "  # Out : titre, date de publication du document (str)\n",
    "  url_biblio = \"https://gallica.bnf.fr/services/OAIRecord?ark=\"+ark\n",
    "  s = requests.get(url_biblio, stream=True)\n",
    "  bibliodico = xmltodict.parse(s.text)\n",
    "  try :\n",
    "    titre = bibliodico[\"results\"][\"title\"]\n",
    "  except :\n",
    "    titre = \"unknown\"\n",
    "  try :\n",
    "    date_pub = bibliodico[\"results\"][\"date\"][\"#text\"]\n",
    "  except :\n",
    "    date_pub = \"unknown\"\n",
    "  return titre, date_pub\n",
    "\n",
    "\n",
    "def nombre_pages(ark):\n",
    "  # In :  identifiant ark\n",
    "  # Out : nombre de pages (int)\n",
    "  PAGINATION_BASEURL = 'https://gallica.bnf.fr/services/Pagination?ark='\n",
    "  url = \"\".join([PAGINATION_BASEURL, ark])\n",
    "  s = requests.get(url, stream=True)\n",
    "  paginationdic = xmltodict.parse(s.text)\n",
    "  nb_pages = int(paginationdic[\"livre\"][\"structure\"][\"nbVueImages\"])\n",
    "  return nb_pages\n",
    "\n",
    "def ark_processing(ark) :\n",
    "  # In :  identifiant ark\n",
    "  # Out : fichier json contenant : \n",
    "    # titre, date, nombre de pages du document\n",
    "    # id, position, contenu des blocs de textes de chaque page\n",
    "\n",
    "  titre, date_pub = infos_doc(ark)\n",
    "  try :\n",
    "    nombre_pagess = nombre_pages(ark)\n",
    "  except :\n",
    "    print(\"Pagination indisponible, document non-téléchargé : \", ark)\n",
    "\n",
    "  print(\"Titre du document : \", titre)\n",
    "  print(\"Dossier de destination : \", destination_dir)\n",
    "  print(\"Téléchargement des blocs de texte :\")\n",
    "\n",
    "  info_doc = {\"Titre\" : titre, \"Publication_Date\" : date_pub, \"Total_Pages\" : nombre_pagess }\n",
    "  global text_blocks \n",
    "  text_blocks = {}\n",
    "\n",
    "  # Pour chaque page du document :\n",
    "  for num_page in range(1,nombre_pagess+1) :\n",
    "  #for num_page in range(1,10) : \n",
    "    print(\"page \",num_page,\" / \",str(nombre_pagess))\n",
    "    # Transforme le fichier OCR ALTO de la page en un dictionnaire :\n",
    "    alto_url = 'https://gallica.bnf.fr/RequestDigitalElement?O='+ark+'&E=ALTO&Deb='+str(num_page)\n",
    "    s = requests.get(alto_url, stream=True)\n",
    "    alto = str(BeautifulSoup(s.content,\"lxml-xml\"))\n",
    "    altodic = xmltodict.parse(alto)\n",
    "    # Si un ou plusieurs blocs de texte sont directement présents dans le PrintSpace : \n",
    "    try :\n",
    "      tb_entry = altodic['alto'][\"Layout\"][\"Page\"][\"PrintSpace\"][\"TextBlock\"]\n",
    "      if isinstance(tb_entry, list) :\n",
    "        for tb in tb_entry :\n",
    "          block_treatment(tb, num_page)\n",
    "        \n",
    "      else :\n",
    "        block_treatment(tb_entry, num_page)\n",
    "    except :\n",
    "      pass\n",
    "    # Si un ou plusieurs blocs composés sont présents dans le PrintSpace : \n",
    "    try :\n",
    "      cb_entry = altodic['alto'][\"Layout\"][\"Page\"][\"PrintSpace\"][\"ComposedBlock\"]\n",
    "      if isinstance(cb_entry, list) :\n",
    "        for cb in cb_entry :\n",
    "          tb_entry = cb[\"TextBlock\"]\n",
    "          if isinstance(tb_entry, list) :\n",
    "            for tb in tb_entry :\n",
    "              block_treatment(tb, num_page)\n",
    "          else :\n",
    "            block_treatment(tb_entry, num_page)\n",
    "      else :\n",
    "        tb_entry = cb_entry[\"TextBlock\"]\n",
    "        if isinstance(tb_entry, list) :\n",
    "          for tb in tb_entry :\n",
    "            block_treatment(tb, num_page)\n",
    "        else :\n",
    "          block_treatment(tb_entry, num_page)\n",
    "    except :\n",
    "      pass\n",
    "  # Création du fichier final :\n",
    "  jsondic = {\"Infos_Doc\" : info_doc, \"Text_Blocks\" : text_blocks}\n",
    "  with open(os.path.join(destination_dir,ark+\"_texte_structure.json\"), 'w') as jout :\n",
    "    json.dump(jsondic, jout)\n",
    "  print(\"Le texte du document a été sauvegardé dans le fichier \", os.path.join(destination_dir,ark+\"_texte_structure.json\"))\n",
    "\n",
    "def bnf2gall(arkbnf):\n",
    "  # In :  identifiant ark au format type cb453908509\n",
    "  # Out : identifiant ark au format type bpt6k9799524x (consultable sur Gallica)\n",
    "  url = \"https://catalogue.bnf.fr/ark:/12148/\"+str(arkbnf)\n",
    "  s = requests.get(url, stream=True)\n",
    "  html = BeautifulSoup(s.content,\"lxml-xml\")\n",
    "  for link in html.findAll('a', {'class': 'exemplaire-action-visualiser'}):\n",
    "    ark = link['href'].split(\"/\")[-1]\n",
    "    return ark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellView": "form",
    "id": "sICRUQT-EL7T"
   },
   "outputs": [],
   "source": [
    "#@markdown ### Définir le répertoire de destination où télécharger le texte des documents :\n",
    "#@markdown Entrer le chemin du répertoire souhaité, puis lancer la cellule.\n",
    "\n",
    "destination_dir = \"\" #@param {type:\"string\"}\n",
    "#@markdown Exemple de chemin:\n",
    "#@markdown /content/drive/My Drive/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "8LNNnDqqEA1V"
   },
   "outputs": [],
   "source": [
    "#@markdown ### A partir d'un identifiant ARK :\n",
    "#@markdown Entrer l'identifiant ARK d'un document, puis lancer la cellule.\n",
    "\n",
    "ark = \"\" #@param {type:\"string\"}\n",
    "#@markdown Exemple d'identifiant:\n",
    "#@markdown bpt6k9799524x ou cb453908509\n",
    "if ark.startswith(\"cb\") :\n",
    "  ark = bnf2gall(ark)\n",
    "ark_processing(ark)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "c0BNtzm_mq0m"
   },
   "outputs": [],
   "source": [
    "#@markdown ### Ou bien à partir d'un fichier excel :\n",
    "#@markdown Entrer le chemin vers le fichier (xslx ou xslm) et l'indice de la colonne, puis lancer la cellule.\n",
    "chemin_fichier_xls = \"\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown Exemple de chemin : /content/drive/MyDrive/Document/documents.xls\n",
    "\n",
    "#@markdown Possibilité de copier/coller le chemin depuis la fenêtre de gauche : onglet \"Fichiers\" -> clic droit sur un dossier -> \"Copier le chemin\"\n",
    "\n",
    "#@markdown ### Puis entrer l'indice de la colonne contenant les liens ARK :\n",
    "colonne_ark = \"\" #@param {type:\"string\"}\n",
    "#@markdown Exemple d'indice : A\n",
    "\n",
    "try :\n",
    "  if not os.path.exists(destination_dir):\n",
    "      os.makedirs(destination_dir)\n",
    "except :\n",
    "  print(\"Le chemin de destination est incorrect\")\n",
    "\n",
    "arks_doc = []\n",
    "\n",
    "# Chargement du fichier xls\n",
    "try :\n",
    "  classeur= load_workbook(chemin_fichier_xls)\n",
    "except :\n",
    "  print(\"Le fichier xls n'a pas été chargé correctement\")\n",
    "\n",
    "for onglet in classeur.sheetnames:\n",
    "  onglet_courant = classeur[onglet]\n",
    "  colonne = onglet_courant[colonne_ark]\n",
    "  for cellule in colonne :\n",
    "    if str(cellule.value).startswith(\"http\") or str(cellule.value).startswith(\"ark\"):\n",
    "      arks_doc.append(str(cellule.value).split(\"/\")[-1].strip())\n",
    "    elif str(cellule.value).startswith(\"cb\") or str(cellule.value).startswith(\"bp\"):\n",
    "      arks_doc.append(str(cellule.value))\n",
    "\n",
    "print(\"{0} liens récupérés dans {1} onglets\".format(len(arks_doc), len(classeur.sheetnames)))\n",
    "\n",
    "arks_doc = set(arks_doc)\n",
    "\n",
    "for ark in arks_doc :\n",
    "  if ark.startswith(\"cb\") :\n",
    "    ark = bnf2gall(ark)\n",
    "  ark_processing(ark)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Nanterre_ModOAP-Telechargement_structure_blocs_texte_Gallica.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
